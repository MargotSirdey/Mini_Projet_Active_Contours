{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yI7wN8JQ22zg"
   },
   "source": [
    "# Active Contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y7hhgrLS3EBw"
   },
   "source": [
    "## Active Contours using Parametric Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "pjLH2x_l32eN",
    "outputId": "0b0cae3d-da77-4a7e-9fb0-a463e41da864"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ndimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-44b86959abcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnt_toolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneral\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnt_toolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lcouret/Documents/GM5/Mini_Projet_Active_Contours/nt_toolbox/general.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# general.py TODO: try to not make use of transform.resize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;31m## commented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ndimage'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from nt_toolbox.general import *\n",
    "from nt_toolbox.signal import *\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "from cmath import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lexfp80H3-XA"
   },
   "source": [
    "#### Polygone initial\n",
    "\n",
    "L'idée est d'associer les contours à des courbes paramétriques. Chaque courbe est discrétisée en p segments et est représentée par un vecteur complexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "w_KKMvLv39WN",
    "outputId": "2cca44b0-fc65-4f64-8f28-d0259bead8dd"
   },
   "outputs": [],
   "source": [
    "gamma0 = np.array([.78, .14, .42, .18, .32, .16, .75, .83, .57, .68, .46, .40, .72, .79, .91, .90]) + 1j*np.array([.87, .82, .75, .63, .34, .17, .08, .46, .50, .25, .27, .57, .73, .57, .75, .79])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4710xraU4HBW"
   },
   "source": [
    "#### Visualisation de la courbe initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "KmrJ7sQl4GXV",
    "outputId": "9859e336-e092-4631-cb46-8f47fb543942"
   },
   "outputs": [],
   "source": [
    "periodize = lambda gamma: concatenate((gamma, [gamma[0]]))\n",
    "def cplot(gamma,s='b',lw=1): \n",
    "    plt.plot(real(periodize(gamma)), imag(periodize(gamma)), s, linewidth=lw)\n",
    "    plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "    \n",
    "cplot(gamma0,'b.-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de points de la courbe discrète (= nombre de segments) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En fonction de la longueur d'un arc (ie: un segment), nous allons échantillonner différemment la courbe. Les lignes de code ci dessous permettent de définir des fonctions utilisées par la suite pour obtenir une courbe \"lisse\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?????\n",
    "\n",
    "\n",
    "# interpc : fonction prenant trois arguments et donnant un complexe\n",
    "#interp : interpole les vecteurs de données xf et real(yf) (ou imag(yf)) et évalue les valeurs obtenues en x\n",
    "interpc = lambda x,xf,yf: interp(x,xf,real(yf)) + 1j * interp(x,xf,imag(yf))\n",
    "#curvabs: fonction prenant en entrée gamma (vecteur), puis retourne un vecteur commençant par 0 et la somme cumulée \n",
    "# de la différence entre gamma sans le premier terme et gamma sans le dernier terme\n",
    "curvabs = lambda gamma: concatenate( ([0], cumsum( 1e-5 + abs(gamma[:-1:]-gamma[1::]) ) ) )\n",
    "\n",
    "#arange(0,p) = vecteur de 0 à p-1 --> est bien composé de p points.\n",
    "#resample1 calcule l'interpolation entre un vecteur de 0 à p-1 pris en entrée et normalisé et le vecteur d  divisé par\n",
    "# d[-1] et gamma\n",
    "resample1 = lambda gamma,d: interpc(arange(0,p)/float(p),  d/d[-1],gamma)\n",
    "#periodize: fonction créée plus haut. Concatène le vecteur d'entrée avec sa première composante\n",
    "resample = lambda gamma: resample1( periodize(gamma), curvabs(periodize(gamma)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbe initiale $\\gamma_{1}(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1 = resample(gamma0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation de la courbe initiale $\\gamma_{1}(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cplot(gamma1, 'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Différence finies\n",
    "On définit ci-dessous des raccourcis pour certaines fonctions : le décalage des données vers la gauche ou vers la droite, le décentrage en amont (forward differences: FwdDiff) et le décentrage en aval (backward differences: BwdDiff).\n",
    "\n",
    "Ces décentrages sont définis respectivement par: $\\nabla f_p = f_{p+1} - f_p$ et $\\nabla f_p = f_p - f_{p-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shiftG = lambda c: concatenate( ([c[-1]],c[:-1:]) ) #Décalage des données (en entrée de la fonction) vers la gauche\n",
    "shiftD = lambda c: concatenate( (c[1::],[c[0]]) ) #Décalages des données vers la droite (donc dernier élement devient le premier)\n",
    "BwdDiff = lambda c: c - shiftG(c) #grad f_p = f_p - f_{p-1}  avec f_{p-1} la courbe paramétrée avec p-1\n",
    "FwdDiff = lambda c: shiftD(c) - c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul de la tangente et de la normale à une courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda v: v/maximum(abs(v),1e-10) #normalisation, fonction maximum utilisée afin de ne pas diviser par 0\n",
    "tangent = lambda gamma: normalize( FwdDiff(gamma) ) #par définition\n",
    "normal = lambda gamma: -1j*tangent(gamma) #par définition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Déplacement de la courbe dans la direction de sa normale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = .03\n",
    "gamma2 = gamma1 + delta * normal(gamma1) #dans la direction de la normale\n",
    "gamma3 = gamma1 - delta * normal(gamma1) #dans la direction opposée à la normale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des courbes définies précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cplot(gamma1, 'k') #noir: courbe initiale lissée (après interpolation)\n",
    "cplot(gamma2, 'r--') #rouge: direction de la normale --> courbe plus à l'extérieur\n",
    "cplot(gamma3, 'b--') #bleu: direction opposée à la normale --> courbe à l'intérieur de la courbe initiale\n",
    "plt.axis('tight') \n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Evolution by mean curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On appelle évolution d'une courbe une série de courbes $\\gamma_s$ indexées par un paramètre d'évolution $s$.\n",
    "Afin d'évaluer la courbe intiale, dans notre cas : $\\gamma_0$, il suffit de minimiser son énergie $E(\\gamma)$ par une méthode de descente du gradient: $$\\frac{\\partial{\\gamma}}{\\partial{s}} = \\nabla E(\\gamma_s)$$\n",
    "\n",
    "Chacune des courbes dans la série peut être pensée comme une surface de Riemann. \n",
    "\n",
    "La manière la plus simple d'obtenir l'évolution d'une courbe est la méthode de \"mean curvature\", que l'on peut traduire par méthode de \"courbure moyenne\". Cela correspond à trouver le minimum de la longueur de la courbe:\n",
    "$$E(\\gamma) = \\int_0^1 ||\\gamma ' (t)|| dt $$\n",
    "\n",
    "Ce minimum sera trouvé grâce à la méthode de descente du gradient.\n",
    "\n",
    "Le gradient de cette longueur est:\n",
    "$$ \\nabla E(\\gamma)(t) = -K_\\gamma(t) n_\\gamma(t) $$\n",
    "\n",
    "avec $K$ la courbure, définie par: $ K_\\gamma(t) = \\frac{1}{||\\gamma'(t)||} <t'_\\gamma(t),n_\\gamma(t)>$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un autre raccourci pour la suite est la fonction normalC, qui sera utilisée pour trouver le gradient $\\nabla E(\\gamma)(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalC = lambda gamma: BwdDiff(tangent(gamma)) / abs( FwdDiff(gamma) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons à présent l'intervalle de temps dt, la durée totale de l'évolution Tmax et le nombre maximal d'itérations niter. A cause de la forte courbure de la forme étudiée, nous devons choisir un intervalle de temps petit. Sinon, la méthode du gradient n'aboutirait pas à un bon résultat puisque $\\gamma$ subirait des changements trop importants au cours de son évolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.001 / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax = 3.0 / 100\n",
    "niter = round(Tmax/dt) #3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\gamma$ au temps $s=0$ prend la valeur de $\\gamma_1$, c'est à dire de la forme initialement étudiée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = gamma1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolution de la courbe $\\gamma$\n",
    "\n",
    "Cette évolution correspond à la méthode de descente du gradient : $$\\gamma = \\gamma - dt * \\nabla E(\\gamma)(t) = \\gamma + dt * K_\\gamma(t) n_\\gamma(t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = gamma + dt * normalC(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ré-échantillonnage de la courbe est appliqué afin de stabiliser la vitesse d'évolution, ceci ayant pour but de pouvoir mener à bien la descente du gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = resample(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 1:  Perform the curve evolution. You need to resample it a few times.\n",
    "\n",
    "Dans cet exercice, nous voulons montrer l'évolution de la courbe paramétrique illustrée avant. Nous choisissons d'afficher 10 courbes intermédiaires différentes du processus. Dans la sortie, la courbe bleue en pointillés la plus interne correspond à la dernière itération, tandis que la plus externe correspond à la première. Les 8 courbes rouges décrivent l'évolution de la courbe en allant de l'extérieur vers l'intérieur.\n",
    "\n",
    "Sur 3000 itérations, 3000 échantillonages ont été effectués, et 10 courbes seulement permettent de bien se rendre compte du cheminement de l'algorithme. Grâce à celles-ci, il est possible de visualiser la descente du gradient. De manière générale, la méthode de descente du gradient converge de moins en moins vite vers un minimum. C'est le cas ici. Plus on s'éloigne de la courbe extérieure (la première itération équivaut à la courbe bleue externe), moins l'écart entre les courbes est grand. Pourtant, l'écart en terme de nombre d'itérations est bien constant entre deux courbes. Cela signifie bien que, pour un même nombre d'itérations, plus on approche d'un minimum, plus la courbe a une faible évolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff = np.around(linspace(1,niter,10)) #liste utilisée pour l'affichage.\n",
    "#On veut avoir 10 courbes : on initialise un vecteur de 10 valeurs réparties équitablement entre 1 et niter=3000.\n",
    "\n",
    "k = 0 #initialisation de la variable parcourant aff\n",
    "\n",
    "for i in range (1,niter+1): #1 à 3000\n",
    "    gamma = resample(gamma + dt*normalC(gamma)) # échantillonage à chaque itération\n",
    "    if i==aff[k] :\n",
    "        if (i==1 or i==niter) :  #courbe la plus au centre ou plus à l'extérieur, ie: 1ère valeur de aff ou dernière\n",
    "            cplot(gamma, 'b--') #alors on dessine en pointillés noirs\n",
    "        else:\n",
    "            cplot(gamma, 'r')\n",
    "             #sinon on dessine en trait plein rouge          \n",
    "        k = k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP872WWD3FDy"
   },
   "source": [
    "### Geodesic Active Contours\n",
    "\n",
    "Le principe est le même que précédemment sauf que nous allons utiliser la longueur pondérée de la courbure. La nouvelle énergie à minimiser est donc :\n",
    "$$E(\\gamma) = \\int_0^1 W(y(t))||\\gamma ' (t)|| dt $$\n",
    "\n",
    "$W > 0$ est une métrique géodésique, c'est-à-dire que ce sont les poids correspondant aux chemins les plus courts, s'ils existent, entre deux points.\n",
    "Là où l'image doit être segmentée, $W$ sera petit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200 #taille de l'image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première étape consiste donc à créer ce vecteur de poids.\n",
    "\n",
    "Pour ce faire, on définit la variable $theta$ comme un tableau de nbumps éléments aléatoirement choisis entre 0 et 1, puis multipliés par $2\\pi$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8718a90d02e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnbumps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbumps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;31m#rayon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#n est la taille de l'image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "nbumps = 40\n",
    "theta = random.rand(nbumps,1)*2*pi\n",
    "\n",
    "r = .6*n/2 #rayon\n",
    "a = np.array([.6*n,.6*n]) #n est la taille de l'image\n",
    "\n",
    "# ??????\n",
    "A0 = int(a[0]) + r*np.cos(theta) \n",
    "A1 = int(a[1]) + r*np.sin(theta) \n",
    "\n",
    "#pour avoir des coordonnées entières\n",
    "x = around(A0) \n",
    "y = around(A1)\n",
    "\n",
    "# ????\n",
    "W = zeros([n,n]) \n",
    "for i in arange(0,nbumps): \n",
    "    W[int(x[i]),int(y[i])] = 1 #coeff de W prennent la valeur de 1 lorsque correspondent à des données sur le cercle?....\n",
    "    \n",
    "W = gaussian_blur(W,6.0) #filtre gaussien appliqué pour le floutage\n",
    "W = rescale(-minimum(W,.05), .3,1) #rééchantillonne les données dans l'intervalle [0.3,1]\n",
    "\n",
    "#Visualisation\n",
    "imageplot(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche désormais à visualiser la norme du gradient des poids : $||\\nabla W||$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = grad(W) #calcul du gradient\n",
    "G = G[:,:,0] + 1j*G[:,:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation de la norme du gradient de W\n",
    "imageplot(abs(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'image ci-dessus paraît complémentaire à l'image précédemment visualisée. Les parties avec plus ou moins d'intensité coïncident dans les deux cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons des fonctions pour évaluer le gradient et le potentiel le long d'une courbe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvalG = lambda gamma: bilinear_interpolate(G, imag(gamma), real(gamma))\n",
    "EvalW = lambda gamma: bilinear_interpolate(W, imag(gamma), real(gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé une courbe circulaire $\\gamma_0$ de rayon $r$, contenant $p$ points sur la courbe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rayon\n",
    "r = .98*n/2 \n",
    "#nombre de points sur la courbe\n",
    "p = 128 \n",
    "\n",
    "#transposée d'un vecteur de longueur p+1 allant de 0 à 2pi (intervalles égaux)\n",
    "theta = transpose( linspace(0, 2*pi, p+1) )\n",
    "\n",
    "#sans la derniere valeur, car cos(0)=cos(2pi) et idem pour sin\n",
    "theta = theta[0:-1] \n",
    "\n",
    "#courbe circulaire\n",
    "gamma0 = n/2 * (1 + 1j) +  r*(np.cos(theta) + 1j*np.sin(theta)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On procède à l'initialisation de $\\gamma_{0}$, des intervalles de temps et du nombre d'itérations.\n",
    "\n",
    "Dans ce cas, $dt$ est plus grand qu'avant car la courbe se situe dans le domaine $\\left[0,n+1\\right]x\\left[0,n+1\\right]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1 #intervalle de temps\n",
    "Tmax = 5000 #durée max\n",
    "niter = round(Tmax/ dt) #nombre d'itérations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2 #largeur du trait\n",
    "plt.clf\n",
    "imageplot(transpose(W)) #visualisation des poids\n",
    "cplot(gamma, 'r', lw) #visualisation de la courbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette courbe, le gradient de l'énergie est :\n",
    "$$ \\nabla E(\\gamma) = -W(\\gamma(t)) K_\\gamma(t)n_\\gamma(t)  +   <\\nabla W(\\gamma(t)),n_\\gamma(t)> n_\\gamma(t). $$\n",
    "\n",
    "Le produit scalaire est défini par la fonction ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotp = lambda c1,c2: real(c1)*real(c2) + imag(c1)*imag(c2) #produit scalaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation de la courbe.\n",
    "\n",
    "Pour ce faire, rappelons que :\n",
    "\n",
    "EvalW(gamma) correspond à $W(\\gamma(t))$,\n",
    "\n",
    "normalC(gamma) correspond à $K_\\gamma(t)n_\\gamma(t)$,\n",
    "\n",
    "dotp(EvalG(gamma), N) correspond à $<\\nabla W(\\gamma(t)),n_\\gamma(t)> $,\n",
    "\n",
    "et enfin normal(gamma) correspond à $n_\\gamma(t)$, la normale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = normal(gamma)\n",
    "g = - EvalW(gamma) * normalC(gamma) + dotp(EvalG(gamma), N) * N\n",
    "gamma = gamma - dt*g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = resample(gamma) #échantillonage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Perform the curve evolution.\n",
    "\n",
    "Nous implémentons dans cet exercice l'évolution du cercle rouge. Nous utilisons la même méthode que dans le premier exercice. Le principe est d'utiliser un vecteur de 10 coefficients (pour les 10 courbes ou 10 étapes d'évolution) uniformément répartis entre 1 et le nombre d'itérations. Le but est en quelque sorte d'\"immortaliser\" l'évolution de la courbe à certaines étapes (ici: 10 à intervalles de temps régulier). On effectue la méthode de descente du gradient pour chacune des itérations. L'immortalisation se traduit par l'affichage d'une courbe rouge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff = around(linspace(1,niter,10)) #affichage de 10 courbes\n",
    "k = 0\n",
    "plt.clf\n",
    "imageplot(transpose(W))\n",
    "for i in range(1,niter+1):\n",
    "    N = normal(gamma)\n",
    "    g = -EvalW(gamma)*normalC(gamma) + dotp(EvalG(gamma),N)*N\n",
    "    gamma = resample(gamma - dt*g)  #échantillonage à chaque boucle  \n",
    "    if i==aff[k]:\n",
    "        if (i==1 or i==niter):\n",
    "            cplot(gamma, 'r',lw) #pour courbes aux extrémités\n",
    "        else:\n",
    "            cplot(gamma, 'r') #pour courbes internes\n",
    "        k = k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medical Image Segmentation\n",
    "\n",
    "Il est aussi possible d'utiliser une métrique basée sur une étude de gradient pour détecter des contours. Appliquons cette méthode sur une image médicale par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 256\n",
    "name = 'nt_toolbox/data/cortex.bmp'\n",
    "f = load_image(name, n) #download image\n",
    "imageplot(f) #affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = grad(f) #calcul du gradient de l'image\n",
    "d0 = np.sqrt(sum(G**2, 2)) #calcul de la norme 2 du gradient\n",
    "imageplot(d0) #affichage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce détecteur de contours est une fonction de la magnitude du gradient et est décroissante. Nous allons tout d'abord flouter l'image par un facteur $a$. Pour cela, on applique une matrice de floutage sur chaque élément de la matrice de l'image.\n",
    "\n",
    "Un exemple de matrice de floutage de type gaussien (dimension 3) :\n",
    "\n",
    "$$ \\frac{1}{a}\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 1 \\\\\n",
    "2 & 4 & 2 \\\\\n",
    "1 & 2 & 1\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2 #coefficient de floutage\n",
    "d = gaussian_blur(d0, a) #d0 image initiale --> floutage gaussien appliqué avec coefficient a\n",
    "imageplot(d) #affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = minimum(d, .4) #minimum entre les valeurs après floutage et 0.4\n",
    "W = rescale(-d, .8, 1) #redéfinition des poids W, échantillonés dans l'intervalle [0.8,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageplot(W) #affichage des poids une fois redéfinis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de points sur la courbe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 128 #nombre de points sur la courbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Create an initial circle $\\gamma_0$ of $p$ points. When plotting the image, you need to transpose it to have axis coherent with the cplot.\n",
    "\n",
    "La courbe initiale est le cercle rouge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redéfinition du rayon et de theta (car n a changé), idem pour gamma0\n",
    "r = .98*n/2;\n",
    "theta = transpose(linspace(0,2*pi,p+1))\n",
    "theta = theta[0:-1] #sans derniere valeur (toujours car cos(0)=cos(2pi))\n",
    "gamma0 = n/2*(1 + 1j) +  r*(np.cos(theta) + 1j*np.sin(theta)) #première courbe = cercle\n",
    "\n",
    "#affectation\n",
    "gamma = gamma0; #initialisation de l'évolution\n",
    "#affichage\n",
    "plt.clf\n",
    "imageplot(transpose(f)) #transposée de l'image selon la consigne\n",
    "cplot(gamma,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passons à la visualisation de l'évolution de la courbe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 2 #intervalle de temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax = 9000 #temps max\n",
    "niter = round(Tmax/ dt) #nombre max d'itérations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: Perform the curve evolution.\n",
    "\n",
    "A nouveau, nous appliquons le même raisonnement pour calculer l'évolution de la courbe.\n",
    "A chaque itération nous ré-évaluons $\\gamma$ et nous l'affichons à 10 étapes équitablement réparties tout au long de l'évolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G= grad(W) # on prend G=grad(W) car on part des poids \n",
    "G = G[:,:,0] + 1j*G[:,:,1] #IDEM: Laura ici tu vas pouvoir nous aider ;) Je sais plus ce que ça fait l'ajout du dernier indice\n",
    "\n",
    "lw = 3\n",
    "aff = around(linspace(1,niter,10))\n",
    "k = 0\n",
    "plt.clf\n",
    "imageplot(transpose(f))\n",
    "for i in range(1,niter+1):\n",
    "    N = normal(gamma)\n",
    "    g = -EvalW(gamma)*normalC(gamma) + dotp(EvalG(gamma), N)*N #réutilisation de EvalW et EvalG (définis avant)\n",
    "    gamma = resample(gamma - dt*g) #échantillonage à chaque itération \n",
    "    if i==aff[k]:\n",
    "        if (i==1 or i==niter):\n",
    "            cplot(gamma, 'r', lw)\n",
    "        else:\n",
    "            cplot(gamma, 'r')\n",
    "            \n",
    "        k = k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution of a Non-closed Curve\n",
    "\n",
    "Pour finir nous allons étudier les courbes non fermées. Afin d'afficher leur évolution il faut introduire des conditions aux frontières. Nommons par exemples ces deux contraintes:\n",
    "$\\gamma(0) = x_0$ et $\\gamma(1) = x_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 256\n",
    "f = load_image('cortex.bmp', n)\n",
    "f = f[45:105, 60:120] #on étudie seulement une partie de l'image\n",
    "n = f.shape[0] #n prend la valeur du nombre de lignes de la matrice de pixels (égale ici au nombre de colonnes = 60)\n",
    "\n",
    "#affichage du carré de l'image étudié\n",
    "imageplot(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: Compute an edge attracting criterion W(x)>0, that is small in area of strong gradient.\n",
    "\n",
    "Le but de cet exercice est d'obtenir l'image précédemment affichée avec des intensités différentes en fonction du gradient. Ainsi, on aura bien une image où les contours pourront être plus facilement repérés.\n",
    "\n",
    "Nous calculons dans un premier temps le gradient de l'image et sa norme. L'idée est ensuite d'accentuer au maximum les propriétés de l'image pour détecter plus facilement les contours. Pour se faire nous filtrons l'image (convolution) par un filtre gaussien. Enfin, nous souhaitons un critère de détection de bords petit là où le gradient est grand. C'est pourquoi nous donnons la valeur de 0.3 à chacun des pixels où le gradient serait plus élevé que ce seuil.\n",
    "\n",
    "Pour affiner le critère de détection, il suffirait alors de diminuer le seuil de tolérance. En prenant par exemple un seuil à 0.2, la visualisation des poids amène à un bord nettement plus distinct. Un seuil de tolérance trop bas n'est en revanche d'aucune utilité. Cela mène à une image où les bords sont très épais. Ceci n'a aucun intérêt car alors, en poussant ce problème à sa limite, toute l'image deviendrait un bord. Nous pouvons noter que ce phénomène d'élargissement progressif des contours est dû au filtre gaussien convolué avant à l'image. Le seuil devenant de plus en plus petit il est normal que de moins en moins de valeurs y soit inférieures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient de f\n",
    "G = grad(f)\n",
    "#G0 : norme 2 du gradient\n",
    "G0 = np.sqrt(sum(G**2, 2))\n",
    "G = gaussian_blur(G0,a) #afin d'accentuer les valeurs dans l'image (--> filtre gaussien)\n",
    "G = minimum(G,.3) #0.3 si \"strong gradient\" ie: dans les régions où G est elevé alors G prendra la valeur de 0.3 (petit)\n",
    "W = rescale(-G,.4,1)\n",
    "plt.clf\n",
    "imageplot(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition des contraintes: $x_0$ et $x_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 4 + 55j\n",
    "x1 = 53 + 4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 128 #nombre de points de la courbe\n",
    "t = transpose(linspace(0, 1, p))\n",
    "gamma0 = t*x1 + (1-t)*x0 #premiere courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = gamma0 #initialisation de l'évolution avec la courbe initiale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf\n",
    "imageplot(transpose(W))\n",
    "cplot(gamma,'r', 2)\n",
    "plt.plot(real(gamma[0]), imag(gamma[0]), 'b.', markersize=20)\n",
    "plt.plot(real(gamma[-1]), imag(gamma[-1]), 'b.', markersize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définitions de fonctions pour les courbes non périodiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvabs = lambda gamma: concatenate( ([0], cumsum( 1e-5 + abs(gamma[:-1:]-gamma[1::]) ) ) )\n",
    "resample1 = lambda gamma,d: interpc(arange(0,p)/float(p-1),  d/d[-1],gamma)\n",
    "resample = lambda gamma: resample1( gamma, curvabs(gamma) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1/10 #intervalle de temps\n",
    "Tmax = 2000*4/ 7\n",
    "niter = round(Tmax/ dt) #nombre maximal d'itérations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6: Perform the curve evolution. Be careful to impose the boundary conditions at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = grad(W) #gradient des poids W\n",
    "G = G[:,:,0] + 1j*G[:,:,1]\n",
    "\n",
    "lw = 3 \n",
    "\n",
    "aff = around(linspace(1,niter,10))\n",
    "\n",
    "k = 0\n",
    "plt.clf\n",
    "imageplot(transpose(f))\n",
    "\n",
    "for i in range(1,niter+1):\n",
    "    N = normal(gamma)\n",
    "    g = -EvalW(gamma)*normalC(gamma) + dotp(EvalG(gamma),N)*N\n",
    "    gamma = resample(gamma - dt*g) #échantillonage à chaque itération\n",
    "    gamma[0] = x0\n",
    "    gamma[-1] = x1 #contraintes aux frontières à ajouter à chaque itération\n",
    "    if i==aff[k]:\n",
    "        if (i==1 or i==niter):\n",
    "            cplot(gamma, 'r', lw)\n",
    "        else:\n",
    "            cplot(gamma, 'r')\n",
    "        k = k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliographie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "machine_learning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
